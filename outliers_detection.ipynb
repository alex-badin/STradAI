{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import glob\n",
    "from os import listdir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# собираем все временные ряды в один (!! потом убирал разницы в местах перехода между разными акциями)\n",
    "directory = 'long_history/*.csv'\n",
    "\n",
    "all_stocks = pd.DataFrame(columns=['Names'])\n",
    "for fname in glob.glob(directory):\n",
    "   df=pd.read_csv(fname)\n",
    "   df['Names'] = fname[13:17]\n",
    "   all_stocks = pd.concat([all_stocks, df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_stocks.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# расчет изменения цены день-к-дню в %\n",
    "all_stocks['close_dif']=(all_stocks['Close'] - all_stocks['Close'].shift(1))/all_stocks['Close'].shift(1)\n",
    "all_stocks['close_dif'].plot.hist(bins=500, figsize=(15,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_stocks.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# список индексов, где слишком сильные отклонения (многие из-за перехода от одной акции к другой) +/- несколько дней\n",
    "# чтобы потом посмотреть, что там случилось\n",
    "strange_index = all_stocks[np.abs(all_stocks['close_dif'])>0.25].index.values.tolist()\n",
    "strange_index.extend([x-1 for x in strange_index])\n",
    "strange_index.extend([x-1 for x in strange_index])\n",
    "strange_index.extend([x+1 for x in strange_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# убираем сравнение там, где переход между акциями\n",
    "all_stocks['close_dif'][all_stocks['Names'] != all_stocks['Names'].shift(1)] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# смотрим странные выбросы - проверял по новостям, действительно ли происходило что-то экстраординарное. Да, происходило.\n",
    "all_stocks[all_stocks.index.isin(strange_index)][50:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  выделяем просто большие изменения (+/- 3% - больше стандартного отклонения). Сколько таких.\n",
    "strange_index1 = all_stocks[np.abs(all_stocks['close_dif'])>0.03].index.values.tolist()\n",
    "len(strange_index1)/all_stocks.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# как распределяются большие изменения\n",
    "stocks_std = all_stocks['close_dif'].std()\n",
    "surges = all_stocks[np.abs(all_stocks['close_dif'])>stocks_std]\n",
    "surges['close_dif'].plot.hist(bins=500, figsize=(25,3), title='Median diff='+str(surges['close_dif'].abs().median()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stocks_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# размечаем дни, когда были скачки > станд.откл-е\n",
    "all_stocks['surges']= np.abs(all_stocks['close_dif']) > stocks_std \n",
    "all_stocks['surges'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# убираем акции, где цена открытия и оборот = 0\n",
    "all_stocks = all_stocks[all_stocks['Open']!=0]\n",
    "all_stocks = all_stocks[all_stocks['Volume']!=0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# проверяем, что нет нулей\n",
    "all_stocks.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# убираем лишние столбцы и сохраняем весь массив\n",
    "all_stocks.drop(['index', 'Dividends','Stock Splits' ], axis=1, inplace=True)\n",
    "all_stocks.to_csv('all_data_surges.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# сохраняем в отдельные файлы\n",
    "names_list = all_stocks['Names'].unique().tolist()\n",
    "for i in names_list:\n",
    "    stock_surge = all_stocks[all_stocks['Names']==i]\n",
    "    # stock_surge.loc[columns='surges', index=0]=False\n",
    "    stock_surge.iloc[0]['surges'] = 'False'\n",
    "    stock_surge.to_csv('long_history/!surges/surges - %s.csv' %(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_stocks[(all_stocks.index>633710) & (all_stocks.index<633716)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_stocks['surges'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create X & Y for Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = pd.read_csv('all_data_surges.csv')\n",
    "df_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['surges'].value_counts(normalize=True)\n",
    "# df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_window = 20\n",
    "counter = 1\n",
    "\n",
    "X=[]\n",
    "Y=[]\n",
    "for counter in range(1, df_all.shape[0]-x_window-1):\n",
    "    if df_all['close_dif'][counter : counter + x_window].isna().sum()==0: #проверяем, что нет NaN (то есть переход между акциями)\n",
    "        X.append(df_all['close_dif'][counter : counter + x_window].values)\n",
    "        Y.append(df_all['surges'][counter + x_window + 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X), len(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_df = pd.DataFrame(X)\n",
    "X_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X_df, Y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X_train), len(X_test), len(Y_train), len(Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegressionCV()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train F1: \"+str(f1_score(Y_train, logreg.predict(X_train))))\n",
    "print(\"Test F1: \"+str(f1_score(Y_test, logreg.predict(X_test))))\n",
    "print(\"Train ROC AUC: \"+str(roc_auc_score(Y_train, logreg.predict(X_train))))\n",
    "print(\"Train ROC AUC: \"+str(roc_auc_score(Y_test, logreg.predict(X_test))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.unique(logreg.predict(X_train), return_counts=True))\n",
    "print(np.unique(logreg.predict(X_test), return_counts=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_c = DecisionTreeClassifier(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_c.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train F1: \"+str(f1_score(Y_train, dt_c.predict(X_train))))\n",
    "print(\"Test F1: \"+str(f1_score(Y_test, dt_c.predict(X_test))))\n",
    "print(\"Train ROC AUC: \"+str(roc_auc_score(Y_train, dt_c.predict(X_train))))\n",
    "print(\"Test ROC AUC: \"+str(roc_auc_score(Y_test, dt_c.predict(X_test))))\n",
    "print(\"Train Recall: \"+str(recall_score(Y_train, dt_c.predict(X_train))))\n",
    "print(\"Test Recall: \"+str(recall_score(Y_test, dt_c.predict(X_test))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_c.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(np.unique(dt_c.predict(X_train), return_counts=True))\n",
    "# print(np.unique(dt_c.predict(X_test), return_counts=True))\n",
    "\n",
    "\n",
    "print(pd.DataFrame(dt_c.predict(X_train))[0].value_counts(normalize=True))\n",
    "print(pd.DataFrame(dt_c.predict(X_test))[0].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disp = ConfusionMatrixDisplay(confusion_matrix=confusion_matrix(Y_test, dt_c.predict(X_test), labels=dt_c.classes_))\n",
    "disp.plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GradBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_cl = GradientBoostingClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_cl.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train F1: \"+str(f1_score(Y_train, gb_cl.predict(X_train))))\n",
    "print(\"Test F1: \"+str(f1_score(Y_test, gb_cl.predict(X_test))))\n",
    "print(\"Train ROC AUC: \"+str(roc_auc_score(Y_train, gb_cl.predict(X_train))))\n",
    "print(\"Test ROC AUC: \"+str(roc_auc_score(Y_test, gb_cl.predict(X_test))))\n",
    "print(\"Train Recall: \"+str(recall_score(Y_train, gb_cl.predict(X_train))))\n",
    "print(\"Test Recall: \"+str(recall_score(Y_test, gb_cl.predict(X_test))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.unique(gb_cl.predict(X_train), return_counts=True))\n",
    "print(np.unique(gb_cl.predict(X_test), return_counts=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomForrest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_cl = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_cl.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train F1: \"+str(f1_score(Y_train, rf_cl.predict(X_train))))\n",
    "print(\"Test F1: \"+str(f1_score(Y_test, rf_cl.predict(X_test))))\n",
    "print(\"Train ROC AUC: \"+str(roc_auc_score(Y_train, rf_cl.predict(X_train))))\n",
    "print(\"Test ROC AUC: \"+str(roc_auc_score(Y_test, rf_cl.predict(X_test))))\n",
    "print(\"Train Recall: \"+str(recall_score(Y_train, rf_cl.predict(X_train))))\n",
    "print(\"Test Recall: \"+str(recall_score(Y_test, rf_cl.predict(X_test))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.unique(rf_cl.predict(X_train), return_counts=True))\n",
    "print(np.unique(rf_cl.predict(X_test), return_counts=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Garbage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = 'long_history/*.csv'\n",
    "li = []\n",
    "for fname in glob.glob(directory):\n",
    "   df=pd.read_csv(fname)\n",
    "   li.append(df)\n",
    "\n",
    "all_stocks = pd.concat(li, axis=0, ignore_index=True)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f04e9d9503fc02916e732e0ca15418c91d0dcb99725da04f8a65fab59f1f0d78"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
